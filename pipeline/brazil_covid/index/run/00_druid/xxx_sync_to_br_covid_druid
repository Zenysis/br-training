#!/bin/bash -eu
set -o pipefail

# It is possible for the 00_index step to exit successfully and not produce a
# datasource_name or datasource_version. This normally happens if the data files
# designated for indexing are the same as the most recently indexed version.
# TODO(stephen): Ideally, Jenkins should just skip the index step entireley.
# Figure out a way to expose the "new data" test so that Jenkins can use it.
if ! [ -f "${PIPELINE_TMP_DIR}/datasource_name" ] ; then
  echo 'No indexing task was created. Skipping'
  exit 0
fi

DATASOURCE_NAME=$(cat "${PIPELINE_TMP_DIR}/datasource_name")
DATASOURCE_VERSION=$(cat "${PIPELINE_TMP_DIR}/datasource_version")
AWS_DRUID_POSTGRES_HOST='172.31.30.208'
BR_COVID_DRUID_POSTGRES_HOST='172.31.23.128'

# Segment metadata table columns to fetch.
COLUMNS='"id", "datasource", "created_date", "start", "end", "partitioned", "version", "used", "payload"'
SELECT_QUERY="\
SELECT
  ${COLUMNS}
FROM
  druid_segments
WHERE
  datasource = '${DATASOURCE_NAME}'
  AND version = '${DATASOURCE_VERSION}'
"
SEGMENT_ROW_FILE="${PIPELINE_TMP_DIR}/segment_db_rows.txt"

echo 'Copying segment metadata from AWS druid to Brazil Covid Druid'
psql \
  -U druid_user \
  -h "${AWS_DRUID_POSTGRES_HOST}" \
  -d druid \
  -c "\copy (${SELECT_QUERY}) TO '${SEGMENT_ROW_FILE}' WITH CSV"

echo 'Importing segment data into Brazil Covid Druid'
psql \
  -U druid_user \
  -h "${BR_COVID_DRUID_POSTGRES_HOST}" \
  -d druid \
  -c "\copy druid_segments (${COLUMNS}) FROM '${SEGMENT_ROW_FILE}' WITH CSV"

# Wait for the new datasource to propagate to the whole cluster
# TODO(stephen): Make a script for this and remove the lazy sleeping
sleep 120